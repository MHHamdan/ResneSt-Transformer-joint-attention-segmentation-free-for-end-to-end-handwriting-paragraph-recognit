{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960a5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mhamdan/seq2seqAttenHTR/Transformer_ocr/src\n"
     ]
    }
   ],
   "source": [
    "%cd src/\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import groupby\n",
    "import h5py\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import cv2\n",
    "from torchvision.models import resnet50, resnet101\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from data import preproc as pp\n",
    "from data import evaluation\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from operator import __add__\n",
    "import random\n",
    "\n",
    "\n",
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "set_random_seeds(random_seed=13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Unmodified from https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "def conv1d(ni:int, no:int, ks:int=1, stride:int=1, padding:int=0, bias:bool=False):\n",
    "    \"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"\n",
    "    conv = nn.Conv1d(ni, no, ks, stride=stride, padding=padding, bias=bias)\n",
    "    nn.init.kaiming_normal_(conv.weight)\n",
    "    if bias: conv.bias.data.zero_()\n",
    "    return nn.utils.spectral_norm(conv)\n",
    "\n",
    "\n",
    "\n",
    "# Adapted from SelfAttention layer at https://github.com/fastai/fastai/blob/5c51f9eabf76853a89a9bc5741804d2ed4407e49/fastai/layers.py\n",
    "# Inspired by https://arxiv.org/pdf/1805.08318.pdf\n",
    "class SimpleSelfAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_in:int, ks=1, sym=False):#, n_out:int):\n",
    "        super().__init__()\n",
    "           \n",
    "        self.conv = conv1d(n_in, n_in, ks, padding=ks//2, bias=False)      \n",
    "       \n",
    "        self.gamma = nn.Parameter(torch.Tensor([0.]))\n",
    "        \n",
    "        self.sym = sym\n",
    "        self.n_in = n_in\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        \n",
    "        if self.sym:\n",
    "            # symmetry hack by https://github.com/mgrankin\n",
    "            c = self.conv.weight.view(self.n_in,self.n_in)\n",
    "            c = (c + c.t())/2\n",
    "            self.conv.weight = c.view(self.n_in,self.n_in,1)\n",
    "                \n",
    "        size = x.size()  \n",
    "        x = x.view(*size[:2],-1)   # (C,N)\n",
    "        \n",
    "        # changed the order of mutiplication to avoid O(N^2) complexity\n",
    "        # (x*xT)*(W*x) instead of (x*(xT*(W*x)))\n",
    "        \n",
    "        convx = self.conv(x)   # (C,C) * (C,N) = (C,N)   => O(NC^2)\n",
    "        xxT = torch.bmm(x,x.permute(0,2,1).contiguous())   # (C,N) * (N,C) = (C,C)   => O(NC^2)\n",
    "        \n",
    "        o = torch.bmm(xxT, convx)   # (C,C) * (C,N) = (C,N)   => O(NC^2)\n",
    "          \n",
    "        o = self.gamma * o + x\n",
    "        \n",
    "          \n",
    "        return o.view(*size).contiguous()        \n",
    "        \n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class OCR(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_len, hidden_dim, nheads,\n",
    "                 num_encoder_layers, num_decoder_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=\"same\"\n",
    "        )\n",
    "#         self.sa1 = SimpleSelfAttention(64)        \n",
    "        self.batch1 = nn.BatchNorm2d(16)\n",
    "        self.act1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        ##CNN Layer 2\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=\"same\"\n",
    "        )\n",
    "#         self.sa2 = SimpleSelfAttention(128)        \n",
    "        self.batch2 = nn.BatchNorm2d(32)\n",
    "        self.act2 = nn.LeakyReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        ##CNN Layer 3\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=\"same\"\n",
    "        )\n",
    "#         self.sa3 = SimpleSelfAttention(256)        \n",
    "        self.batch3 = nn.BatchNorm2d(48)\n",
    "        self.act3 = nn.LeakyReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        ##CNN Layer 4\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=48, out_channels=64, kernel_size=3, stride=1, padding=\"same\"\n",
    "        )\n",
    "#         self.sa4 = SimpleSelfAttention(512)        \n",
    "        self.batch4 = nn.BatchNorm2d(64)\n",
    "        self.act4 = nn.LeakyReLU()\n",
    "        ##CNN Layer 5\n",
    "        self.drop3 = nn.Dropout(0.2)\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=80, kernel_size=3, stride=1, padding=\"same\"\n",
    "        )\n",
    "#         self.sa5 = SimpleSelfAttention(512)        \n",
    "        self.batch5 = nn.BatchNorm2d(80)\n",
    "        self.act5 = nn.LeakyReLU()\n",
    "        \n",
    "        self.conv = nn.Conv2d(80, hidden_dim, 1)\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads with length of vocab\n",
    "        # DETR used basic 3 layer MLP for output\n",
    "        self.vocab = nn.Linear(hidden_dim,vocab_len)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.decoder = nn.Embedding(vocab_len, hidden_dim)\n",
    "        self.query_pos = PositionalEncoding(hidden_dim, .2)\n",
    "\n",
    "        # spatial positional encodings, sine positional encoding can be used.\n",
    "        # Detr baseline uses sine positional encoding.\n",
    "        self.row_embed = nn.Parameter(torch.rand(128, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(16, hidden_dim // 2))\n",
    "        self.trg_mask = None\n",
    "  \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "        mask = mask.masked_fill(mask==1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def get_feature(self,x):\n",
    "        x = self.conv1(x)\n",
    "#         x = self.sa1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        ##CNN Layer 2\n",
    "        x = self.conv2(x)\n",
    "#         x = self.sa2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        ##CNN Layer 3\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv3(x)\n",
    "#         x = self.sa3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.pool3(x)\n",
    "        ##CNN Layer 4\n",
    "        x = self.drop2(x)\n",
    "        x = self.conv4(x)\n",
    "#         x = self.sa4(x)        \n",
    "        x = self.batch4(x)\n",
    "        x = self.act4(x)\n",
    "        ##CNN Layer 5\n",
    "        x = self.drop3(x)\n",
    "        x = self.conv5(x)\n",
    "#         x = self.sa5(x)        \n",
    "        x = self.batch5(x)\n",
    "        x = self.act5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == 0).transpose(0, 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, trg):\n",
    "        # propagate inputs through ResNet-101 up to avg-pool layer\n",
    "        x = self.get_feature(inputs)\n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(x)\n",
    "        # construct positional encodings\n",
    "        bs,_,H, W = h.shape\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "        # generating subsequent mask for target\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(trg.shape[1]).to(trg.device)\n",
    "\n",
    "        # Padding mask\n",
    "        trg_pad_mask = self.make_len_mask(trg)\n",
    "\n",
    "        # Getting postional encoding for target\n",
    "        trg = self.decoder(trg)\n",
    "        trg = self.query_pos(trg)\n",
    "        \n",
    "        output = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1), trg.permute(1,0,2), tgt_mask=self.trg_mask, \n",
    "                                  tgt_key_padding_mask=trg_pad_mask.permute(1,0))\n",
    "\n",
    "        return self.vocab(output.transpose(0,1))\n",
    "\n",
    "\n",
    "def make_model(vocab_len, hidden_dim=256, nheads=4,\n",
    "                 num_encoder_layers=4, num_decoder_layers=4):\n",
    "    \n",
    "    return OCR(vocab_len, hidden_dim, nheads,\n",
    "                 num_encoder_layers, num_decoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90b998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = make_model(vocab_len=99,hidden_dim=256, nheads=4,\n",
    "#                  num_encoder_layers=4, num_decoder_layers=4)\n",
    "\n",
    "# img = torch.rand(1,1,1024,128)\n",
    "# trg = torch.randint(1,5,(1,128))\n",
    "# x = model(img,trg)\n",
    "\n",
    "\"\"\"\n",
    "Uses generator functions to supply train/test with data.\n",
    "Image renderings and text are created on the fly each time.\n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator(Dataset):\n",
    "    \"\"\"Generator class with data streaming\"\"\"\n",
    "\n",
    "    def __init__(self, source, split, transform, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.split = split\n",
    "        self.dataset = dict()\n",
    "\n",
    "        with h5py.File(source, \"r\") as f:\n",
    "            self.dataset[self.split] = dict()\n",
    "\n",
    "            self.dataset[self.split]['dt'] = np.array(f[self.split]['dt'])\n",
    "            self.dataset[self.split]['gt'] = np.array(f[self.split]['gt'])\n",
    "          \n",
    "            randomize = np.arange(len(self.dataset[self.split]['gt']))\n",
    "            np.random.seed(42)\n",
    "            np.random.shuffle(randomize)\n",
    "\n",
    "            self.dataset[self.split]['dt'] = self.dataset[self.split]['dt'][randomize]\n",
    "            self.dataset[self.split]['gt'] = self.dataset[self.split]['gt'][randomize]\n",
    "\n",
    "            # decode sentences from byte\n",
    "            self.dataset[self.split]['gt'] = [x.decode() for x in self.dataset[self.split]['gt']]\n",
    "            \n",
    "        self.size = len(self.dataset[self.split]['gt'])\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = self.dataset[self.split]['dt'][i]\n",
    "        \n",
    "        #making image compatible with resnet\n",
    "#         img = cv2.transpose(img)\n",
    "        img = np.repeat(img[..., np.newaxis],3, -1).astype(\"float32\")   \n",
    "#         img = pp.normalization(img).astype(\"float32\")\n",
    "#         img = img.astype(\"float32\")\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img)\n",
    "            img = aug['image']\n",
    "            \n",
    "#             img = self.transform(img)\n",
    "            \n",
    "        y_train = self.tokenizer.encode(self.dataset[self.split]['gt'][i]) \n",
    "        \n",
    "        #padding till max length\n",
    "        y_train = np.pad(y_train, (0, self.tokenizer.maxlen - len(y_train)))\n",
    "\n",
    "        gt = torch.Tensor(y_train)\n",
    "\n",
    "        return img, gt          \n",
    "\n",
    "    def __len__(self):\n",
    "      return self.size\n",
    "\n",
    "class Tokenizer():\n",
    "    \"\"\"Manager tokens functions and charset/dictionary properties\"\"\"\n",
    "\n",
    "    def __init__(self, chars, max_text_length=128):\n",
    "        self.PAD_TK, self.UNK_TK,self.SOS,self.EOS = \"¶\", \"¤\", \"SOS\", \"EOS\"\n",
    "        self.chars = [self.PAD_TK] + [self.UNK_TK ]+ [self.SOS] + [self.EOS] +list(chars)\n",
    "        self.PAD = self.chars.index(self.PAD_TK)\n",
    "        self.UNK = self.chars.index(self.UNK_TK)\n",
    "\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.maxlen = max_text_length\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text to vector\"\"\"\n",
    "        text = unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        groups = [\"\".join(group) for _, group in groupby(text)]\n",
    "        text = \"\".join([self.UNK_TK.join(list(x)) if len(x) > 1 else x for x in groups])\n",
    "        encoded = []\n",
    "\n",
    "        text = ['SOS'] + list(text) + ['EOS']\n",
    "        for item in text:\n",
    "            index = self.chars.index(item)\n",
    "            index = self.UNK if index == -1 else index\n",
    "            encoded.append(index)\n",
    "\n",
    "        return np.asarray(encoded)\n",
    "\n",
    "    def decode(self, text):\n",
    "        \"\"\"Decode vector to text\"\"\"\n",
    "        \n",
    "        decoded = \"\".join([self.chars[int(x)] for x in text if x > -1])\n",
    "        decoded = self.remove_tokens(decoded)\n",
    "        decoded = pp.text_standardize(decoded)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def remove_tokens(self, text):\n",
    "        \"\"\"Remove tokens (PAD) from text\"\"\"\n",
    "\n",
    "        return text.replace(self.PAD_TK, \"\").replace(self.UNK_TK, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f4bdedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ../data/iam_only_illumintaion.hdf5\n",
      "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 200\n",
    "\n",
    "# define paths\n",
    "#change paths accordingly\n",
    "source = 'iam_only_illumintaion'\n",
    "source_path = '../data/{}.hdf5'.format(source)\n",
    "\n",
    "# define input size, number max of chars per line and list of valid chars\n",
    "input_size = (1024, 128, 1)\n",
    "max_text_length = 128\n",
    "charset_base = string.printable[:95]\n",
    "# charset_base = string.printable[:36].lower() + string.printable[36+26:95].lower() \n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"charset:\", charset_base)\n",
    "\n",
    "\n",
    "import torchvision.transforms as T\n",
    "local_rank = 1\n",
    "device = torch.device(\"cuda:{}\".format(local_rank))\n",
    "\n",
    "# transform = T.Compose([\n",
    "#     T.ToTensor()])\n",
    "tokenizer = Tokenizer(charset_base)\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "if True:\n",
    "\n",
    "    transform_train = albumentations.Compose([\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.MotionBlur(p=1, blur_limit=8),\n",
    "                albumentations.OpticalDistortion(p=1, distort_limit=0.05),\n",
    "                albumentations.GaussNoise(p=1, var_limit=(10.0, 100.0)),\n",
    "                albumentations.RandomBrightnessContrast(p=1, brightness_limit=0.2),\n",
    "                albumentations.Downscale(p=1, scale_min=0.3, scale_max=0.5),\n",
    "            ],\n",
    "            p=.5,\n",
    "        ),\n",
    "#         albumentations.Resize(224,224),\n",
    "        albumentations.Normalize(),\n",
    "        albumentations.pytorch.ToTensorV2()\n",
    "\n",
    "    ])\n",
    "\n",
    "    transform_valid = albumentations.Compose(\n",
    "        [\n",
    "#         albumentations.Resize(224,224),            \n",
    "            albumentations.Normalize(),\n",
    "            albumentations.pytorch.ToTensorV2()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "else:\n",
    "    transform_train = albumentations.Compose(\n",
    "        [\n",
    "#         albumentations.Resize(224,224),            \n",
    "            albumentations.Normalize(),\n",
    "            albumentations.pytorch.ToTensorV2()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    transform_valid = albumentations.Compose(\n",
    "        [\n",
    "#         albumentations.Resize(224,224),\n",
    "            \n",
    "            albumentations.Normalize(),\n",
    "            albumentations.pytorch.ToTensorV2()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(DataGenerator(source_path,'train',transform_train, tokenizer), batch_size=batch_size,  shuffle=True,num_workers=6)\n",
    "val_loader = torch.utils.data.DataLoader(DataGenerator(source_path,'valid',transform_valid, tokenizer), batch_size=batch_size, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5636d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhamdan/miniconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "\n",
    "model = make_model( vocab_len=tokenizer.vocab_size,hidden_dim=256, nheads=4,\n",
    "                 num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers)\n",
    "\n",
    "            \n",
    "# init_funcs = {\n",
    "# 1: lambda x: torch.nn.init.normal_(x, mean=0., std=1.), # can be bias\n",
    "# 2: lambda x: torch.nn.init.xavier_normal_(x, gain=1.), # can be weight\n",
    "# 3: lambda x: torch.nn.init.xavier_uniform_(x, gain=1.), # can be conv1D filter\n",
    "# 4: lambda x: torch.nn.init.xavier_uniform_(x, gain=1.), # can be conv2D filter\n",
    "# \"default\": lambda x: torch.nn.init.constant(x, 1.), # everything else\n",
    "# }\n",
    "# for p in model.parameters():\n",
    "#     init_func = init_funcs.get(len(p.shape), init_funcs[\"default\"])\n",
    "#     init_func(p)\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx=0, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "\n",
    "smoothing = .4\n",
    "criterion = LabelSmoothing(size=tokenizer.vocab_size, padding_idx=0, smoothing=smoothing)\n",
    "criterion.to(device)\n",
    "lr = .5e-05# learnig rte\n",
    "backbone_lr = .003\n",
    "# if not args.pretrained:\n",
    "#     backbone_lr = backbone_lr*10\n",
    "\n",
    "# param_dicts = [\n",
    "#     {\"params\": [p for n, p in model.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "#     {\n",
    "#         \"params\": [p for n, p in model.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "#         \"lr\": backbone_lr,\n",
    "#     },\n",
    "# ]\n",
    "\n",
    "scheduler_factor = .8\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr,weight_decay=.0004)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=scheduler_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a20de52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"../output_cnnt/only_illumination//{}_best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef5231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimiser,dataloader):\n",
    " \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch, (imgs, labels_y,) in enumerate(dataloader):\n",
    "          imgs = imgs.to(device)\n",
    "          labels_y = labels_y.to(device)\n",
    "    \n",
    "          optimiser.zero_grad()\n",
    "          output = model(imgs.float(),labels_y.long()[:,:-1])\n",
    " \n",
    "          loss = criterion(output.log_softmax(-1).contiguous().view(-1, tokenizer.vocab_size), labels_y[:,1:].contiguous().view(-1).long()) \n",
    " \n",
    "          loss.backward()\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 0.2)\n",
    "          optimizer.step()\n",
    "          total_loss += loss.item()\n",
    " \n",
    "    return total_loss / len(dataloader)\n",
    " \n",
    "def evaluate(model, criterion, dataloader,):\n",
    " \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    cer = 0\n",
    "    with torch.no_grad():\n",
    "      for batch, (imgs, labels_y,) in enumerate(dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels_y = labels_y.to(device)\n",
    " \n",
    "            output = model(imgs.float(),labels_y.long()[:,:-1])\n",
    "            o = output.argmax(-1)\n",
    "            predicts = list(map(lambda x : tokenizer.decode(x).replace('SOS','').replace('EOS',''),o))\n",
    "            gt = list(map(lambda x : tokenizer.decode(x).replace('SOS','').replace('EOS',''),labels_y))\n",
    "            cer += evaluation.ocr_metrics(predicts=predicts,\n",
    "                                   ground_truth=gt)[0]\n",
    "            \n",
    "            loss = criterion(output.log_softmax(-1).contiguous().view(-1, tokenizer.vocab_size), labels_y[:,1:].contiguous().view(-1).long())\n",
    "  \n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    " \n",
    "    return epoch_loss / len(dataloader), cer\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    " \n",
    "best_valid_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e01254a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 learning rate[5e-06]\n",
      "Time: 2m 54s\n",
      "Train Loss: 553.045\n",
      "Val   Loss: 477.872\n",
      "cer: 81.738\n",
      "Epoch: 02 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 500.978\n",
      "Val   Loss: 464.637\n",
      "cer: 82.186\n",
      "Epoch: 03 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 489.961\n",
      "Val   Loss: 458.168\n",
      "cer: 81.807\n",
      "Epoch: 04 learning rate[5e-06]\n",
      "Time: 2m 54s\n",
      "Train Loss: 484.298\n",
      "Val   Loss: 455.900\n",
      "cer: 81.932\n",
      "Epoch: 05 learning rate[5e-06]\n",
      "Time: 2m 55s\n",
      "Train Loss: 480.653\n",
      "Val   Loss: 453.041\n",
      "cer: 81.196\n",
      "Epoch: 06 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 477.854\n",
      "Val   Loss: 451.665\n",
      "cer: 81.545\n",
      "Epoch: 07 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 475.755\n",
      "Val   Loss: 448.927\n",
      "cer: 81.018\n",
      "Epoch: 08 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 473.399\n",
      "Val   Loss: 447.581\n",
      "cer: 80.770\n",
      "Epoch: 09 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 471.360\n",
      "Val   Loss: 445.643\n",
      "cer: 80.343\n",
      "Epoch: 10 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 469.653\n",
      "Val   Loss: 443.710\n",
      "cer: 80.262\n",
      "Epoch: 11 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 467.838\n",
      "Val   Loss: 442.139\n",
      "cer: 80.226\n",
      "Epoch: 12 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 466.119\n",
      "Val   Loss: 440.780\n",
      "cer: 79.958\n",
      "Epoch: 13 learning rate[5e-06]\n",
      "Time: 2m 55s\n",
      "Train Loss: 464.626\n",
      "Val   Loss: 438.642\n",
      "cer: 79.441\n",
      "Epoch: 14 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 462.657\n",
      "Val   Loss: 436.973\n",
      "cer: 79.432\n",
      "Epoch: 15 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 461.167\n",
      "Val   Loss: 435.008\n",
      "cer: 79.459\n",
      "Epoch: 16 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 459.634\n",
      "Val   Loss: 432.652\n",
      "cer: 78.733\n",
      "Epoch: 17 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 458.077\n",
      "Val   Loss: 432.176\n",
      "cer: 78.690\n",
      "Epoch: 18 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 456.608\n",
      "Val   Loss: 430.590\n",
      "cer: 78.584\n",
      "Epoch: 19 learning rate[5e-06]\n",
      "Time: 2m 55s\n",
      "Train Loss: 455.091\n",
      "Val   Loss: 428.537\n",
      "cer: 78.336\n",
      "Epoch: 20 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 453.628\n",
      "Val   Loss: 427.494\n",
      "cer: 78.323\n",
      "Epoch: 21 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 452.391\n",
      "Val   Loss: 425.240\n",
      "cer: 77.917\n",
      "Epoch: 22 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 450.938\n",
      "Val   Loss: 424.764\n",
      "cer: 77.838\n",
      "Epoch: 23 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 449.464\n",
      "Val   Loss: 423.659\n",
      "cer: 77.372\n",
      "Epoch: 24 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 447.881\n",
      "Val   Loss: 421.474\n",
      "cer: 77.516\n",
      "Epoch: 25 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 446.593\n",
      "Val   Loss: 420.197\n",
      "cer: 77.525\n",
      "Epoch: 26 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 444.930\n",
      "Val   Loss: 418.316\n",
      "cer: 77.072\n",
      "Epoch: 27 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 443.479\n",
      "Val   Loss: 416.746\n",
      "cer: 76.546\n",
      "Epoch: 28 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 442.179\n",
      "Val   Loss: 416.634\n",
      "cer: 76.985\n",
      "Epoch: 29 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 440.777\n",
      "Val   Loss: 415.635\n",
      "cer: 76.940\n",
      "Epoch: 30 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 439.638\n",
      "Val   Loss: 413.125\n",
      "cer: 76.258\n",
      "Epoch: 31 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 438.160\n",
      "Val   Loss: 411.986\n",
      "cer: 76.200\n",
      "Epoch: 32 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 436.762\n",
      "Val   Loss: 412.385\n",
      "cer: 76.101\n",
      "Epoch: 33 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 435.270\n",
      "Val   Loss: 410.422\n",
      "cer: 75.685\n",
      "Epoch: 34 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 434.091\n",
      "Val   Loss: 411.292\n",
      "cer: 76.034\n",
      "Epoch: 35 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 432.577\n",
      "Val   Loss: 409.984\n",
      "cer: 76.028\n",
      "Epoch: 36 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 431.355\n",
      "Val   Loss: 405.533\n",
      "cer: 75.142\n",
      "Epoch: 37 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 430.107\n",
      "Val   Loss: 404.409\n",
      "cer: 75.131\n",
      "Epoch: 38 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 429.088\n",
      "Val   Loss: 403.719\n",
      "cer: 74.919\n",
      "Epoch: 39 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 427.874\n",
      "Val   Loss: 403.807\n",
      "cer: 75.038\n",
      "Epoch: 40 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 426.533\n",
      "Val   Loss: 402.607\n",
      "cer: 74.856\n",
      "Epoch: 41 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 425.227\n",
      "Val   Loss: 401.115\n",
      "cer: 74.530\n",
      "Epoch: 42 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 424.296\n",
      "Val   Loss: 400.257\n",
      "cer: 74.298\n",
      "Epoch: 43 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 423.351\n",
      "Val   Loss: 398.869\n",
      "cer: 74.171\n",
      "Epoch: 44 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 422.080\n",
      "Val   Loss: 398.689\n",
      "cer: 73.865\n",
      "Epoch: 45 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 421.214\n",
      "Val   Loss: 397.273\n",
      "cer: 73.605\n",
      "Epoch: 46 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 419.629\n",
      "Val   Loss: 395.302\n",
      "cer: 73.755\n",
      "Epoch: 47 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 418.898\n",
      "Val   Loss: 394.534\n",
      "cer: 73.892\n",
      "Epoch: 48 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 417.877\n",
      "Val   Loss: 395.226\n",
      "cer: 73.344\n",
      "Epoch: 49 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 417.107\n",
      "Val   Loss: 392.677\n",
      "cer: 73.404\n",
      "Epoch: 50 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 415.811\n",
      "Val   Loss: 392.516\n",
      "cer: 73.440\n",
      "Epoch: 51 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 415.162\n",
      "Val   Loss: 391.363\n",
      "cer: 73.199\n",
      "Epoch: 52 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 413.945\n",
      "Val   Loss: 390.872\n",
      "cer: 72.925\n",
      "Epoch: 53 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 412.934\n",
      "Val   Loss: 389.600\n",
      "cer: 73.069\n",
      "Epoch: 54 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 412.006\n",
      "Val   Loss: 388.779\n",
      "cer: 72.561\n",
      "Epoch: 55 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 410.911\n",
      "Val   Loss: 388.412\n",
      "cer: 72.887\n",
      "Epoch: 56 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 410.283\n",
      "Val   Loss: 386.376\n",
      "cer: 72.663\n",
      "Epoch: 57 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 409.194\n",
      "Val   Loss: 386.896\n",
      "cer: 72.665\n",
      "Epoch: 58 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 408.579\n",
      "Val   Loss: 385.580\n",
      "cer: 72.700\n",
      "Epoch: 59 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 407.694\n",
      "Val   Loss: 385.968\n",
      "cer: 72.271\n",
      "Epoch: 60 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 406.648\n",
      "Val   Loss: 385.521\n",
      "cer: 72.741\n",
      "Epoch: 61 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 406.146\n",
      "Val   Loss: 383.113\n",
      "cer: 72.207\n",
      "Epoch: 62 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 405.666\n",
      "Val   Loss: 383.426\n",
      "cer: 72.361\n",
      "Epoch: 63 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 404.490\n",
      "Val   Loss: 382.666\n",
      "cer: 73.321\n",
      "Epoch: 64 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 403.905\n",
      "Val   Loss: 382.651\n",
      "cer: 72.338\n",
      "Epoch: 65 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 402.831\n",
      "Val   Loss: 381.787\n",
      "cer: 73.227\n",
      "Epoch: 66 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 402.289\n",
      "Val   Loss: 380.019\n",
      "cer: 71.714\n",
      "Epoch: 67 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 401.787\n",
      "Val   Loss: 378.593\n",
      "cer: 71.416\n",
      "Epoch: 68 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 400.885\n",
      "Val   Loss: 380.064\n",
      "cer: 71.326\n",
      "Epoch: 69 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 399.878\n",
      "Val   Loss: 377.919\n",
      "cer: 72.989\n",
      "Epoch: 70 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 399.036\n",
      "Val   Loss: 378.907\n",
      "cer: 73.211\n",
      "Epoch: 71 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 398.783\n",
      "Val   Loss: 376.690\n",
      "cer: 71.445\n",
      "Epoch: 72 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 398.020\n",
      "Val   Loss: 376.665\n",
      "cer: 71.070\n",
      "Epoch: 73 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 397.318\n",
      "Val   Loss: 376.131\n",
      "cer: 71.405\n",
      "Epoch: 74 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 396.821\n",
      "Val   Loss: 376.197\n",
      "cer: 72.639\n",
      "Epoch: 75 learning rate[5e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 396.183\n",
      "Val   Loss: 374.931\n",
      "cer: 71.448\n",
      "Epoch: 76 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 395.365\n",
      "Val   Loss: 373.696\n",
      "cer: 70.463\n",
      "Epoch: 77 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 394.544\n",
      "Val   Loss: 375.359\n",
      "cer: 71.577\n",
      "Epoch: 78 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 394.348\n",
      "Val   Loss: 373.633\n",
      "cer: 70.805\n",
      "Epoch: 79 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 393.621\n",
      "Val   Loss: 372.171\n",
      "cer: 70.104\n",
      "Epoch: 80 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 392.576\n",
      "Val   Loss: 372.790\n",
      "cer: 70.211\n",
      "Epoch: 81 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 392.257\n",
      "Val   Loss: 371.756\n",
      "cer: 71.111\n",
      "Epoch: 82 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 391.799\n",
      "Val   Loss: 371.676\n",
      "cer: 71.836\n",
      "Epoch: 83 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 390.894\n",
      "Val   Loss: 371.786\n",
      "cer: 70.296\n",
      "Epoch: 84 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 390.716\n",
      "Val   Loss: 371.202\n",
      "cer: 70.027\n",
      "Epoch: 85 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 390.253\n",
      "Val   Loss: 370.741\n",
      "cer: 70.109\n",
      "Epoch: 86 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 389.478\n",
      "Val   Loss: 369.833\n",
      "cer: 72.245\n",
      "Epoch: 87 learning rate[5e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3m 0s\n",
      "Train Loss: 388.915\n",
      "Val   Loss: 369.582\n",
      "cer: 70.059\n",
      "Epoch: 88 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 388.587\n",
      "Val   Loss: 370.301\n",
      "cer: 70.488\n",
      "Epoch: 89 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 388.052\n",
      "Val   Loss: 369.865\n",
      "cer: 69.979\n",
      "Epoch: 90 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 387.147\n",
      "Val   Loss: 368.169\n",
      "cer: 71.176\n",
      "Epoch: 91 learning rate[5e-06]\n",
      "Time: 2m 59s\n",
      "Train Loss: 386.964\n",
      "Val   Loss: 368.666\n",
      "cer: 69.614\n",
      "Epoch: 92 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 386.151\n",
      "Val   Loss: 367.487\n",
      "cer: 69.868\n",
      "Epoch: 93 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 385.460\n",
      "Val   Loss: 366.873\n",
      "cer: 70.814\n",
      "Epoch: 94 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 385.327\n",
      "Val   Loss: 366.821\n",
      "cer: 69.111\n",
      "Epoch: 95 learning rate[5e-06]\n",
      "Time: 3m 1s\n",
      "Train Loss: 384.645\n",
      "Val   Loss: 366.177\n",
      "cer: 69.736\n",
      "Epoch: 96 learning rate[5e-06]\n",
      "Time: 3m 0s\n",
      "Train Loss: 384.426\n",
      "Val   Loss: 366.822\n",
      "cer: 69.682\n",
      "Epoch: 97 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 383.802\n",
      "Val   Loss: 366.584\n",
      "cer: 69.274\n",
      "Epoch: 98 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 383.008\n",
      "Val   Loss: 365.590\n",
      "cer: 69.496\n",
      "Epoch: 99 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 382.565\n",
      "Val   Loss: 365.395\n",
      "cer: 68.968\n",
      "Epoch: 100 learning rate[5e-06]\n",
      "Time: 2m 55s\n",
      "Train Loss: 382.273\n",
      "Val   Loss: 366.032\n",
      "cer: 69.310\n",
      "Epoch: 101 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 381.832\n",
      "Val   Loss: 364.859\n",
      "cer: 69.076\n",
      "Epoch: 102 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 381.210\n",
      "Val   Loss: 363.849\n",
      "cer: 68.833\n",
      "Epoch: 103 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 380.828\n",
      "Val   Loss: 363.762\n",
      "cer: 68.718\n",
      "Epoch: 104 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 380.385\n",
      "Val   Loss: 363.039\n",
      "cer: 69.097\n",
      "Epoch: 105 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 379.850\n",
      "Val   Loss: 365.052\n",
      "cer: 68.920\n",
      "Epoch: 106 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 379.464\n",
      "Val   Loss: 362.212\n",
      "cer: 69.014\n",
      "Epoch: 107 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 379.133\n",
      "Val   Loss: 362.687\n",
      "cer: 68.955\n",
      "Epoch: 108 learning rate[5e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 378.822\n",
      "Val   Loss: 362.085\n",
      "cer: 69.559\n",
      "Epoch: 109 learning rate[5e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 378.038\n",
      "Val   Loss: 361.575\n",
      "cer: 69.030\n",
      "Epoch: 110 learning rate[5e-06]\n",
      "Time: 2m 53s\n",
      "Train Loss: 377.766\n",
      "Val   Loss: 361.363\n",
      "cer: 69.241\n",
      "Epoch: 111 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 377.277\n",
      "Val   Loss: 362.161\n",
      "cer: 68.699\n",
      "Epoch: 112 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 376.802\n",
      "Val   Loss: 363.965\n",
      "cer: 68.909\n",
      "Epoch: 113 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 376.358\n",
      "Val   Loss: 361.309\n",
      "cer: 68.995\n",
      "Epoch: 114 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 375.790\n",
      "Val   Loss: 361.085\n",
      "cer: 68.936\n",
      "Epoch: 115 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 375.390\n",
      "Val   Loss: 360.165\n",
      "cer: 68.282\n",
      "Epoch: 116 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 375.001\n",
      "Val   Loss: 360.226\n",
      "cer: 68.223\n",
      "Epoch: 117 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 374.898\n",
      "Val   Loss: 360.088\n",
      "cer: 68.362\n",
      "Epoch: 118 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 374.091\n",
      "Val   Loss: 359.934\n",
      "cer: 68.120\n",
      "Epoch: 119 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 373.690\n",
      "Val   Loss: 358.786\n",
      "cer: 68.692\n",
      "Epoch: 120 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 373.595\n",
      "Val   Loss: 358.711\n",
      "cer: 67.872\n",
      "Epoch: 121 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 373.091\n",
      "Val   Loss: 359.795\n",
      "cer: 68.327\n",
      "Epoch: 122 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 372.675\n",
      "Val   Loss: 360.929\n",
      "cer: 67.995\n",
      "Epoch: 123 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 372.047\n",
      "Val   Loss: 359.800\n",
      "cer: 67.737\n",
      "Epoch: 124 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 372.004\n",
      "Val   Loss: 358.471\n",
      "cer: 68.044\n",
      "Epoch: 125 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 371.586\n",
      "Val   Loss: 358.358\n",
      "cer: 67.700\n",
      "Epoch: 126 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 371.096\n",
      "Val   Loss: 357.035\n",
      "cer: 67.908\n",
      "Epoch: 127 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 370.752\n",
      "Val   Loss: 358.556\n",
      "cer: 67.626\n",
      "Epoch: 128 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 370.337\n",
      "Val   Loss: 356.605\n",
      "cer: 67.798\n",
      "Epoch: 129 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 369.849\n",
      "Val   Loss: 356.729\n",
      "cer: 67.867\n",
      "Epoch: 130 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 369.416\n",
      "Val   Loss: 358.134\n",
      "cer: 67.736\n",
      "Epoch: 131 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 369.244\n",
      "Val   Loss: 355.842\n",
      "cer: 67.451\n",
      "Epoch: 132 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 368.674\n",
      "Val   Loss: 355.959\n",
      "cer: 67.746\n",
      "Epoch: 133 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 368.564\n",
      "Val   Loss: 356.651\n",
      "cer: 68.635\n",
      "Epoch: 134 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 368.079\n",
      "Val   Loss: 355.386\n",
      "cer: 67.555\n",
      "Epoch: 135 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 367.788\n",
      "Val   Loss: 355.882\n",
      "cer: 68.069\n",
      "Epoch: 136 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 367.198\n",
      "Val   Loss: 354.791\n",
      "cer: 67.522\n",
      "Epoch: 137 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 366.806\n",
      "Val   Loss: 355.547\n",
      "cer: 67.365\n",
      "Epoch: 138 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 366.593\n",
      "Val   Loss: 354.454\n",
      "cer: 67.669\n",
      "Epoch: 139 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 366.268\n",
      "Val   Loss: 354.188\n",
      "cer: 67.255\n",
      "Epoch: 140 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 365.680\n",
      "Val   Loss: 353.793\n",
      "cer: 67.331\n",
      "Epoch: 141 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 365.489\n",
      "Val   Loss: 355.114\n",
      "cer: 68.663\n",
      "Epoch: 142 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 365.319\n",
      "Val   Loss: 353.876\n",
      "cer: 67.779\n",
      "Epoch: 143 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 364.699\n",
      "Val   Loss: 354.288\n",
      "cer: 68.083\n",
      "Epoch: 144 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 364.622\n",
      "Val   Loss: 353.735\n",
      "cer: 67.472\n",
      "Epoch: 145 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 363.945\n",
      "Val   Loss: 354.036\n",
      "cer: 67.175\n",
      "Epoch: 146 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 363.658\n",
      "Val   Loss: 353.871\n",
      "cer: 67.217\n",
      "Epoch: 147 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 363.409\n",
      "Val   Loss: 352.823\n",
      "cer: 67.273\n",
      "Epoch: 148 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 363.167\n",
      "Val   Loss: 353.198\n",
      "cer: 67.431\n",
      "Epoch: 149 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 362.777\n",
      "Val   Loss: 352.832\n",
      "cer: 67.083\n",
      "Epoch: 150 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 362.559\n",
      "Val   Loss: 353.802\n",
      "cer: 67.478\n",
      "Epoch: 151 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 362.386\n",
      "Val   Loss: 351.748\n",
      "cer: 66.980\n",
      "Epoch: 152 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 361.716\n",
      "Val   Loss: 353.220\n",
      "cer: 67.408\n",
      "Epoch: 153 learning rate[5e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 361.212\n",
      "Val   Loss: 351.777\n",
      "cer: 67.517\n",
      "Epoch: 154 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 361.132\n",
      "Val   Loss: 351.920\n",
      "cer: 67.711\n",
      "Epoch: 155 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 360.706\n",
      "Val   Loss: 352.285\n",
      "cer: 66.965\n",
      "Epoch: 156 learning rate[5e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 360.262\n",
      "Val   Loss: 351.795\n",
      "cer: 66.890\n",
      "Epoch: 157 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 359.918\n",
      "Val   Loss: 351.384\n",
      "cer: 67.213\n",
      "Epoch: 158 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 359.540\n",
      "Val   Loss: 350.834\n",
      "cer: 67.049\n",
      "Epoch: 159 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 359.537\n",
      "Val   Loss: 352.608\n",
      "cer: 67.899\n",
      "Epoch: 160 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 359.342\n",
      "Val   Loss: 350.802\n",
      "cer: 66.849\n",
      "Epoch: 161 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 358.994\n",
      "Val   Loss: 352.081\n",
      "cer: 67.266\n",
      "Epoch: 162 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 358.663\n",
      "Val   Loss: 351.041\n",
      "cer: 67.055\n",
      "Epoch: 163 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 358.377\n",
      "Val   Loss: 350.163\n",
      "cer: 66.768\n",
      "Epoch: 164 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 358.130\n",
      "Val   Loss: 351.049\n",
      "cer: 66.954\n",
      "Epoch: 165 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 357.864\n",
      "Val   Loss: 350.080\n",
      "cer: 66.650\n",
      "Epoch: 166 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 357.835\n",
      "Val   Loss: 350.172\n",
      "cer: 66.963\n",
      "Epoch: 167 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 357.480\n",
      "Val   Loss: 350.068\n",
      "cer: 66.753\n",
      "Epoch: 168 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 357.263\n",
      "Val   Loss: 350.108\n",
      "cer: 66.642\n",
      "Epoch: 169 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 356.983\n",
      "Val   Loss: 349.668\n",
      "cer: 66.649\n",
      "Epoch: 170 learning rate[4.000000000000001e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2m 49s\n",
      "Train Loss: 356.777\n",
      "Val   Loss: 350.487\n",
      "cer: 66.886\n",
      "Epoch: 171 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 356.464\n",
      "Val   Loss: 349.770\n",
      "cer: 66.932\n",
      "Epoch: 172 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 356.250\n",
      "Val   Loss: 350.051\n",
      "cer: 67.000\n",
      "Epoch: 173 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 355.799\n",
      "Val   Loss: 349.448\n",
      "cer: 66.842\n",
      "Epoch: 174 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 355.589\n",
      "Val   Loss: 349.000\n",
      "cer: 66.658\n",
      "Epoch: 175 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 355.520\n",
      "Val   Loss: 349.027\n",
      "cer: 66.647\n",
      "Epoch: 176 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 355.395\n",
      "Val   Loss: 349.430\n",
      "cer: 66.597\n",
      "Epoch: 177 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 354.642\n",
      "Val   Loss: 348.950\n",
      "cer: 66.837\n",
      "Epoch: 178 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 354.903\n",
      "Val   Loss: 349.371\n",
      "cer: 66.759\n",
      "Epoch: 179 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 354.411\n",
      "Val   Loss: 348.842\n",
      "cer: 66.695\n",
      "Epoch: 180 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 354.357\n",
      "Val   Loss: 348.566\n",
      "cer: 66.573\n",
      "Epoch: 181 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 354.545\n",
      "Val   Loss: 348.587\n",
      "cer: 66.366\n",
      "Epoch: 182 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 353.592\n",
      "Val   Loss: 347.922\n",
      "cer: 66.353\n",
      "Epoch: 183 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 353.374\n",
      "Val   Loss: 348.550\n",
      "cer: 67.539\n",
      "Epoch: 184 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 50s\n",
      "Train Loss: 353.201\n",
      "Val   Loss: 348.478\n",
      "cer: 66.583\n",
      "Epoch: 185 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 353.258\n",
      "Val   Loss: 348.164\n",
      "cer: 66.756\n",
      "Epoch: 186 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 49s\n",
      "Train Loss: 352.738\n",
      "Val   Loss: 348.184\n",
      "cer: 66.420\n",
      "Epoch: 187 learning rate[4.000000000000001e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 352.685\n",
      "Val   Loss: 348.260\n",
      "cer: 67.831\n",
      "Epoch: 188 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 352.452\n",
      "Val   Loss: 347.696\n",
      "cer: 66.600\n",
      "Epoch: 189 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 58s\n",
      "Train Loss: 351.973\n",
      "Val   Loss: 347.606\n",
      "cer: 67.244\n",
      "Epoch: 190 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.758\n",
      "Val   Loss: 348.407\n",
      "cer: 67.865\n",
      "Epoch: 191 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.694\n",
      "Val   Loss: 348.157\n",
      "cer: 66.594\n",
      "Epoch: 192 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.417\n",
      "Val   Loss: 347.270\n",
      "cer: 66.286\n",
      "Epoch: 193 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.085\n",
      "Val   Loss: 347.790\n",
      "cer: 66.398\n",
      "Epoch: 194 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.218\n",
      "Val   Loss: 347.243\n",
      "cer: 66.455\n",
      "Epoch: 195 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.178\n",
      "Val   Loss: 348.088\n",
      "cer: 66.544\n",
      "Epoch: 196 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 351.011\n",
      "Val   Loss: 347.246\n",
      "cer: 67.025\n",
      "Epoch: 197 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 350.309\n",
      "Val   Loss: 347.062\n",
      "cer: 66.787\n",
      "Epoch: 198 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 56s\n",
      "Train Loss: 350.584\n",
      "Val   Loss: 347.094\n",
      "cer: 67.195\n",
      "Epoch: 199 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 350.003\n",
      "Val   Loss: 347.219\n",
      "cer: 67.432\n",
      "Epoch: 200 learning rate[3.2000000000000007e-06]\n",
      "Time: 2m 57s\n",
      "Train Loss: 350.016\n",
      "Val   Loss: 347.151\n",
      "cer: 66.674\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for epoch in range(200):\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02}\", \"learning rate{}\".format(lr_scheduler.get_last_lr()))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, criterion, optimizer, train_loader)\n",
    "    valid_loss, cer = evaluate(model, criterion, val_loader)\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, time.time())\n",
    "\n",
    "    c += 1\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), target_path.format(\"loss\"))\n",
    "        c=0\n",
    "\n",
    "    if c > 4:\n",
    "        # decrease lr if loss does not deacrease after 5 steps\n",
    "        lr_scheduler.step()\n",
    "        c = 0\n",
    "                   \n",
    "    if epoch%10==0:\n",
    "        torch.save(model.state_dict(), target_path.format(\"epoch\"))\n",
    "\n",
    "\n",
    "    print(f\"Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Train Loss: {train_loss:.3f}\")\n",
    "    print(f\"Val   Loss: {valid_loss:.3f}\")\n",
    "    print(f\"cer: {cer:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for epoch in range(300):\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02}\", \"learning rate{}\".format(lr_scheduler.get_last_lr()))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, criterion, optimizer, train_loader)\n",
    "    valid_loss, cer = evaluate(model, criterion, val_loader)\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, time.time())\n",
    "\n",
    "    c += 1\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), target_path.format(\"loss\"))\n",
    "        c=0\n",
    "\n",
    "    if c > 4:\n",
    "        # decrease lr if loss does not deacrease after 5 steps\n",
    "        lr_scheduler.step()\n",
    "        c = 0\n",
    "                   \n",
    "    if epoch%10==0:\n",
    "        torch.save(model.state_dict(), target_path.format(\"epoch\"))\n",
    "\n",
    "\n",
    "    print(f\"Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Train Loss: {train_loss:.3f}\")\n",
    "    print(f\"Val   Loss: {valid_loss:.3f}\")\n",
    "    print(f\"cer: {cer:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa8dae07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = torch.load(\"../output_cnnt/only_illumination/loss_best.hdf5\")\n",
    "model.load_state_dict(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282fe9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(model,imgs):\n",
    "    x = model.conv(model.get_feature(imgs))\n",
    "    bs,_,H, W = x.shape\n",
    "    pos = torch.cat([\n",
    "            model.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            model.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "    return model.transformer.encoder(pos +  0.1 * x.flatten(2).permute(2, 0, 1))\n",
    "    \n",
    "\n",
    "def test(model, test_loader, max_text_length):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    gt = []\n",
    "    imgs = []\n",
    "    c=0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            src, trg = batch\n",
    "            imgs.append(src.flatten(0,1))\n",
    "            src, trg = src.to(device), trg.to(device)            \n",
    "            memory = get_memory(model,src.float())\n",
    "            out_indexes = [tokenizer.chars.index('SOS'), ]\n",
    "            for i in range(max_text_length):\n",
    "                mask = model.generate_square_subsequent_mask(i+1).to(device)\n",
    "                trg_tensor = torch.LongTensor(out_indexes).unsqueeze(1).to(device)\n",
    "                output = model.vocab(model.transformer.decoder(model.query_pos(model.decoder(trg_tensor)), memory,tgt_mask=mask))\n",
    "                out_token = output.argmax(2)[-1].item()\n",
    "                out_indexes.append(out_token)\n",
    "                if out_token == tokenizer.chars.index('EOS'):\n",
    "                    break\n",
    "            predicts.append(tokenizer.decode(out_indexes))\n",
    "            gt.append(tokenizer.decode(trg.flatten(0,1)))\n",
    "#             if c==5:\n",
    "#                 break\n",
    "            c+=1\n",
    "    return predicts, gt, imgs\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(DataGenerator(source_path,'test',transform_valid, tokenizer), batch_size=1, shuffle=False)\n",
    "\n",
    "predicts, gt, imgs = test(model,test_loader , max_text_length)\n",
    "\n",
    "predicts = list(map(lambda x : x.replace('SOS','').replace('EOS',''),predicts))\n",
    "gt = list(map(lambda x : x.replace('SOS','').replace('EOS',''),gt))\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts=predicts,\n",
    "                                  ground_truth=gt,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f602034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55101188, 0.75791297, 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c5954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f1e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
