{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1458677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mhamdan/seq2seqAttenHTR/Transformer_ocr/src\n"
     ]
    }
   ],
   "source": [
    "%cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f373fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import groupby\n",
    "import h5py\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50, resnet101\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from data import preproc as pp\n",
    "from data import evaluation\n",
    "from torch.utils.data import Dataset\n",
    "import time\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "import pytorch_lightning as pl \n",
    "import clip as openai\n",
    "from PIL import Image\n",
    "from clip.clip import _transform as preprocess\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=128):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class OCR(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_len, hidden_dim, nheads,\n",
    "                 num_encoder_layers, num_decoder_layers):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.backbone, _ = openai.load(\"RN50x16\", device=\"cpu\")\n",
    "        del self.backbone.transformer, self.backbone.visual.attnpool\n",
    "        \n",
    "        _ = self.backbone.to(device)\n",
    "        for name,p in self.backbone.named_parameters():\n",
    "            if \"visual\" not in name or \"attnpool\" in name:\n",
    "                p.requires_grad =  False\n",
    "            elif \"visual\" in name and \"bn\" in name:\n",
    "                p.requires_grad =  False\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        # create conversion layer\n",
    "        self.conv = nn.Conv2d(3072, hidden_dim, 1)\n",
    "\n",
    "        # create a default PyTorch transformer\n",
    "        self.transformer = nn.Transformer(\n",
    "            hidden_dim, nheads, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "        # prediction heads with length of vocab\n",
    "        # DETR used basic 3 layer MLP for output\n",
    "        self.vocab = nn.Linear(hidden_dim,vocab_len)\n",
    "\n",
    "        # output positional encodings (object queries)\n",
    "        self.decoder = nn.Embedding(vocab_len, hidden_dim)\n",
    "        self.query_pos = PositionalEncoding(hidden_dim, .2)\n",
    "\n",
    "        # spatial positional encodings, sine positional encoding can be used.\n",
    "        # Detr baseline uses sine positional encoding.\n",
    "        self.row_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.col_embed = nn.Parameter(torch.rand(50, hidden_dim // 2))\n",
    "        self.trg_mask = None\n",
    "  \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = torch.triu(torch.ones(sz, sz), 1)\n",
    "        mask = mask.masked_fill(mask==1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def get_feature(self, x):\n",
    "        x = self.backbone.visual.conv1(x)\n",
    "        x = self.backbone.visual.bn1(x)   \n",
    "        x = self.backbone.visual.relu(x)\n",
    "        x = self.backbone.visual.conv2(x)\n",
    "        x = self.backbone.visual.bn2(x)   \n",
    "        x = self.backbone.visual.relu(x)\n",
    "        x = self.backbone.visual.conv3(x)\n",
    "        x = self.backbone.visual.bn3(x)   \n",
    "        x = self.backbone.visual.relu(x)\n",
    "\n",
    "        x = self.backbone.visual.avgpool(x)\n",
    "        x = self.backbone.visual.layer1(x)\n",
    "        x = self.backbone.visual.layer2(x)\n",
    "        x = self.backbone.visual.layer3(x)\n",
    "        x = self.backbone.visual.layer4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == 0).transpose(0, 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, trg):\n",
    "        # propagate inputs through ResNet-101 up to avg-pool layer\n",
    "        x = self.get_feature(inputs)\n",
    "\n",
    "        # convert from 2048 to 256 feature planes for the transformer\n",
    "        h = self.conv(x)\n",
    "\n",
    "        # construct positional encodings\n",
    "        bs,_,H, W = h.shape\n",
    "        pos = torch.cat([\n",
    "            self.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            self.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "        # generating subsequent mask for target\n",
    "        if self.trg_mask is None or self.trg_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_subsequent_mask(trg.shape[1]).to(trg.device)\n",
    "\n",
    "        # Padding mask\n",
    "        trg_pad_mask = self.make_len_mask(trg)\n",
    "\n",
    "        # Getting postional encoding for target\n",
    "        trg = self.decoder(trg)\n",
    "        trg = self.query_pos(trg)\n",
    "        \n",
    "        output = self.transformer(pos + 0.1 * h.flatten(2).permute(2, 0, 1), trg.permute(1,0,2), tgt_mask=self.trg_mask, \n",
    "                                  tgt_key_padding_mask=trg_pad_mask.permute(1,0))\n",
    "\n",
    "        return self.vocab(output.transpose(0,1))\n",
    "\n",
    "\n",
    "def make_model(vocab_len, hidden_dim=256, nheads=4,\n",
    "                 num_encoder_layers=4, num_decoder_layers=4):\n",
    "    \n",
    "    return OCR(vocab_len, hidden_dim, nheads,\n",
    "                 num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "\"\"\"\n",
    "Uses generator functions to supply train/test with data.\n",
    "Image renderings and text are created on the fly each time.\n",
    "\"\"\"\n",
    "\n",
    "class DataGenerator(Dataset):\n",
    "    \"\"\"Generator class with data streaming\"\"\"\n",
    "\n",
    "    def __init__(self, source, split, transform, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.split = split\n",
    "        self.dataset = dict()\n",
    "\n",
    "        with h5py.File(source, \"r\") as f:\n",
    "            self.dataset[self.split] = dict()\n",
    "\n",
    "            self.dataset[self.split]['dt'] = np.array(f[self.split]['dt'])\n",
    "            self.dataset[self.split]['gt'] = np.array(f[self.split]['gt'])\n",
    "          \n",
    "            randomize = np.arange(len(self.dataset[self.split]['gt']))\n",
    "            np.random.seed(42)\n",
    "            np.random.shuffle(randomize)\n",
    "\n",
    "            self.dataset[self.split]['dt'] = self.dataset[self.split]['dt'][randomize]\n",
    "            self.dataset[self.split]['gt'] = self.dataset[self.split]['gt'][randomize]\n",
    "\n",
    "            # decode sentences from byte\n",
    "            self.dataset[self.split]['gt'] = [x.decode() for x in self.dataset[self.split]['gt']]\n",
    "            \n",
    "        self.size = len(self.dataset[self.split]['gt'])\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img = self.dataset[self.split]['dt'][i]\n",
    "        \n",
    "        #making image compatible with resnet\n",
    "        img = np.repeat(img[..., np.newaxis],3, -1).astype(\"float32\")   \n",
    "#         img = pp.normalization(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img)\n",
    "            img = aug['image']\n",
    "        y_train = self.tokenizer.encode(self.dataset[self.split]['gt'][i]) \n",
    "        \n",
    "        #padding till max length\n",
    "        y_train = np.pad(y_train, (0, self.tokenizer.maxlen - len(y_train)))\n",
    "\n",
    "        gt = torch.Tensor(y_train)\n",
    "\n",
    "        return img, gt          \n",
    "\n",
    "    def __len__(self):\n",
    "      return self.size\n",
    "\n",
    "class Tokenizer():\n",
    "    \"\"\"Manager tokens functions and charset/dictionary properties\"\"\"\n",
    "\n",
    "    def __init__(self, chars, max_text_length=128):\n",
    "        self.PAD_TK, self.UNK_TK,self.SOS,self.EOS = \"¶\", \"¤\", \"SOS\", \"EOS\"\n",
    "        self.chars = [self.PAD_TK] + [self.UNK_TK ]+ [self.SOS] + [self.EOS] +list(chars)\n",
    "        self.PAD = self.chars.index(self.PAD_TK)\n",
    "        self.UNK = self.chars.index(self.UNK_TK)\n",
    "\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.maxlen = max_text_length\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Encode text to vector\"\"\"\n",
    "        text = unicodedata.normalize(\"NFKD\", text).encode(\"ASCII\", \"ignore\").decode(\"ASCII\").lower()\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        groups = [\"\".join(group) for _, group in groupby(text)]\n",
    "        text = \"\".join([self.UNK_TK.join(list(x)) if len(x) > 1 else x for x in groups])\n",
    "        encoded = []\n",
    "\n",
    "        text = ['SOS'] + list(text) + ['EOS']\n",
    "        for item in text:\n",
    "            index = self.chars.index(item)\n",
    "            index = self.UNK if index == -1 else index\n",
    "            encoded.append(index)\n",
    "\n",
    "        return np.asarray(encoded)\n",
    "\n",
    "    def decode(self, text):\n",
    "        \"\"\"Decode vector to text\"\"\"\n",
    "        \n",
    "        decoded = \"\".join([self.chars[int(x)] for x in text if x > -1])\n",
    "        decoded = self.remove_tokens(decoded)\n",
    "        decoded = pp.text_standardize(decoded)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def remove_tokens(self, text):\n",
    "        \"\"\"Remove tokens (PAD) from text\"\"\"\n",
    "\n",
    "        return text.replace(self.PAD_TK, \"\").replace(self.UNK_TK, \"\")\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d035ba12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ../data/iam.hdf5\n",
      "output ../output/iam\n",
      "charset: 0123456789abcdefghijklmnopqrstuvwxyz!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "#change paths accordingly\n",
    "source = 'iam'\n",
    "source_path = '../data/{}.hdf5'.format(source)\n",
    "output_path = os.path.join(\"..\", \"output\", source)\n",
    "nput_size = (1024, 128, 1)\n",
    "max_text_length = 128\n",
    "# charset_base = string.printable[:95]\n",
    "charset_base = string.printable[:36].lower() + string.printable[36+26:95].lower() \n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"output\", output_path)\n",
    "print(\"charset:\", charset_base)\n",
    "\n",
    "import torchvision.transforms as T\n",
    "device = \"cuda:3\"\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()])\n",
    "tokenizer = Tokenizer(charset_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5615f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "\n",
    "transform = albumentations.Compose([\n",
    "#     albumentations.RandomContrast(),\n",
    "#   albumentations.MotionBlur(p=.2),\n",
    "#   albumentations.OpticalDistortion(p=.3),\n",
    "#   albumentations.GaussNoise(p=.2),\n",
    "#     albumentations.RandomBrightnessContrast(p=0.2), \n",
    "        albumentations.Normalize(),\n",
    "    \n",
    "    albumentations.pytorch.transforms.ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2a24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e2a865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = make_model( vocab_len=tokenizer.vocab_size,hidden_dim=256, nheads=4,\n",
    "                 num_encoder_layers=4, num_decoder_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cec9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bd60e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load(\"../output/iam/checkpoint_weights_iam_small_clip_resnet50x16_aug_lr_uniform.hdf5\", map_location={\"cuda:0\":\"cpu\"})\n",
    "\n",
    "f = {}\n",
    "for i in d:\n",
    "    f[i.replace(\"module.\",\"\")] = d[i]\n",
    "\n",
    "model.load_state_dict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(model,imgs):\n",
    "    x = model.conv(model.get_feature(imgs))\n",
    "    bs,_,H, W = x.shape\n",
    "    pos = torch.cat([\n",
    "            model.col_embed[:W].unsqueeze(0).repeat(H, 1, 1),\n",
    "            model.row_embed[:H].unsqueeze(1).repeat(1, W, 1),\n",
    "        ], dim=-1).flatten(0, 1).unsqueeze(1)\n",
    "\n",
    "    return model.transformer.encoder(pos +  0.1 * x.flatten(2).permute(2, 0, 1))\n",
    "    \n",
    "\n",
    "def test(model, test_loader, max_text_length):\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    gt = []\n",
    "    imgs = []\n",
    "    c=0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            src, trg = batch\n",
    "            imgs.append(src.flatten(0,1))\n",
    "            src, trg = src.to(device), trg.to(device)            \n",
    "            memory = get_memory(model,src.float())\n",
    "            out_indexes = [tokenizer.chars.index('SOS'), ]\n",
    "            for i in range(max_text_length):\n",
    "                mask = model.generate_square_subsequent_mask(i+1).to(device)\n",
    "                trg_tensor = torch.LongTensor(out_indexes).unsqueeze(1).to(device)\n",
    "                output = model.vocab(model.transformer.decoder(model.query_pos(model.decoder(trg_tensor)), memory,tgt_mask=mask))\n",
    "                out_token = output.argmax(2)[-1].item()\n",
    "                out_indexes.append(out_token)\n",
    "                if out_token == tokenizer.chars.index('EOS'):\n",
    "                    break\n",
    "            predicts.append(tokenizer.decode(out_indexes))\n",
    "            gt.append(tokenizer.decode(trg.flatten(0,1)))\n",
    "            if c==500:\n",
    "                break\n",
    "            c+=1\n",
    "    return predicts, gt, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db698eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(DataGenerator(source_path,'test',transform, tokenizer), batch_size=1, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e1d783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicts, gt, imgs = test(model, test_loader, max_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1953020",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = list(map(lambda x : x.replace('SOS','').replace('EOS',''),predicts))\n",
    "gt = list(map(lambda x : x.replace('SOS','').replace('EOS',''),gt))\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts=predicts,\n",
    "                                  ground_truth=gt,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbdded47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06382166, 0.1924706 , 0.78842315])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5701708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qeite unable to explain why he should feel',\n",
       " 'meet the deanes , and as scon as guy had',\n",
       " 'the harges and cranle egrough to cure our',\n",
       " \"you not killed ! ' because we know all things , ' the\",\n",
       " 'with the possibility of faulty design . \" he held',\n",
       " 'all due deference , miss deame - come off it ! ',\n",
       " 'st would have been acceptable to all concemed',\n",
       " 'to make you understard just what happened',\n",
       " 'course of action should be . first to avoid the',\n",
       " 'i stamp department ) while sally sulled at home . ',\n",
       " 'bill is good man , and breno buckis raived on lake . ',\n",
       " 'then what of the oultural life ? did this per - ',\n",
       " \"auttered together . ' do you say that you poor\",\n",
       " 'sally and of course mrs reptimus , for surely',\n",
       " 'did you come from ? \" the judge raid in',\n",
       " 'purice mevice affice . \" you wow \\' t 5 tell sont nine , ',\n",
       " 'soud , \" said mogan thomas tartly . ',\n",
       " 'was clear . the street was quiet and',\n",
       " ' \\' land . \" what have you got in that bask , prie ! ',\n",
       " 'that they use dan as a specimen demonsha - ',\n",
       " 'gave the impression of having been thought out and',\n",
       " 'career . now he realised that he was entrusting not only',\n",
       " \"gay , and don ' t even contemplate throwing\",\n",
       " 'think and plan and know . those who know',\n",
       " 'we must learn all we can about',\n",
       " 'mut have been worth a great deal to the propriet fors',\n",
       " 'with their wings soon died away as the wonderful',\n",
       " ' \" but something very untoward has',\n",
       " 'be open . das . he entered , and reated himself',\n",
       " 'so unexpected , so nusual , that an be the',\n",
       " 'stell . \" doe answered for her . \" fust kell . never able to',\n",
       " 'mole consciously or unconscinbly symublised , any - ',\n",
       " \"we ' we had pericles ' entive mort equipment removed\",\n",
       " \"about this house ? and fill ' s school ? - and ' \",\n",
       " \"of suspense . ' it will be intereting\",\n",
       " 'plump hand towards her grand pianos , etcoc : ',\n",
       " 'them out . just what there orders will be , we don t',\n",
       " 'him at the temporary boudge over the',\n",
       " 'the vestibule , the two men were well',\n",
       " 'and no doubt he would come back soon and',\n",
       " 'as it obviously appeared to everyone else . ',\n",
       " 'then philip was so certain that nicholas',\n",
       " 'with at here purty . that was why',\n",
       " 'mantle , and said with such',\n",
       " 'depth in this particular instance . fingesed',\n",
       " 'anigthing , \" jay told herself desperately , ',\n",
       " 'breatifuslfust . it was a beantiful day , as firsts - of fue',\n",
       " ' \" pon \\' t . be such a baby ! \" they were goinge',\n",
       " 'opportunity presented itself . he must',\n",
       " 'at the centre of each cirde stood persounel',\n",
       " 'what did it say ? rystry toor ? \" ol , very constic , that',\n",
       " 'some weakness , and find a way of fighting',\n",
       " 'heedlessly thrown down their souls . ',\n",
       " 'her eyes and reached for her address book . \" \\' \\' iell',\n",
       " 'myself ? but was it so ? i allowed myself',\n",
       " 'him a great deal better than you do . ',\n",
       " 'our position . the driver must sound his horn',\n",
       " 'it seened to the frightened judge',\n",
       " 'off it \" sait bawley . \" the propriiictor of the paily',\n",
       " 'in halting gatois that \" 3ristak pistak piers \" lad',\n",
       " 'nigel from the back . d . ) - and all . ',\n",
       " ' \" no . \" she ald phil gubbins , a junior',\n",
       " 'mr . wise the tule mantacturer , to have the same addolesent',\n",
       " 'so once again the metaphysics were depressing , ',\n",
       " 'moment in disqust . she was fully aware that cavin',\n",
       " \"a submariner ' s wife needed to be spared as mucit\",\n",
       " 'this is the testingtime for all . the affair blows up into',\n",
       " 'the was writing something is bis',\n",
       " 'gut no whrsles so as you can see . just you',\n",
       " ' \" there are all sorts of wonder - ',\n",
       " 'and of the wharf . but by piessing',\n",
       " 'boxer , to the back , and made room for her',\n",
       " 'things we will tell you all who make the journey from',\n",
       " 'of water , tossed out a string of silvery',\n",
       " 'he was better ; he had made a',\n",
       " 'though half an hour ago she had',\n",
       " 'walked , or dove , or waited as a person possessed of',\n",
       " 'own veranda , that he had taken the liberty of',\n",
       " 'ifor was . for thise was his gange hand , ',\n",
       " 'youlation that washomoidal . ',\n",
       " 'inte draws , airching a big mas by a',\n",
       " 'miserable enough my having to take my',\n",
       " 'i knen hes was responsalle for',\n",
       " 'puriously on the road . not a nign of',\n",
       " \"when hervent to morfydled ' s house , all\",\n",
       " \"worry , fudge . sig wind like that can ' t\",\n",
       " 'afraid , with a frosf shaped like the heel',\n",
       " ' \\' now , who has any food ? \" he asked hopefully . ',\n",
       " 'and their lunar and earthly repercussions , to lnch',\n",
       " 'be the same , if you knor what i mean . \" jou sound',\n",
       " 'his ticket - punch brevously . peered out of',\n",
       " 'to receive a summars . 19 caned see that the seprimans',\n",
       " 'dinas advertiser . but the london papers ignored',\n",
       " \"with dan maffrey ' s aim to avenge himself\",\n",
       " 'man of the road his freedom of decision , and',\n",
       " 'of despair gay knew thoct of course',\n",
       " 'last impertinent remark . \" with four other people - ',\n",
       " 'selves in there geal to get their oders and to cary',\n",
       " 'gublis boy thought he saw you at the dood of trouble . ',\n",
       " 'speed records on the woy in . ',\n",
       " \"but after that slight slip of the tougue on higl ' s peart the had\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082bc6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
